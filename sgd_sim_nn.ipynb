{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['GLOG_minloglevel']     = '2'\n",
    "os.environ['TF_USE_LEGACY_KERAS']  = '1'\n",
    "\n",
    "devnull = open(os.devnull, 'w')\n",
    "old_stderr = sys.stderr\n",
    "sys.stderr = devnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from typing import Iterable\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import trange\n",
    "import warnings\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.stderr = old_stderr\n",
    "devnull.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dev in tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(dev, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_cifar10(verbose = False):\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    \n",
    "    X_train = X_train.astype(np.float32) / 255.0\n",
    "    X_test = X_test.astype(np.float32) / 255.0\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"---------------CIFAR10---------------\")\n",
    "        print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
    "        print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "def obtain_cifar100(verbose = False):\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "    y_train = keras.utils.to_categorical(y_train, 100)\n",
    "    y_test = keras.utils.to_categorical(y_test, 100)\n",
    "    \n",
    "    X_train = X_train.astype(np.float32) / 255.0\n",
    "    X_test = X_test.astype(np.float32) / 255.0\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"---------------CIFAR100---------------\")\n",
    "        print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
    "        print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dense_nn(input_shape, width = 1024, num_classes = 10):\n",
    "    inp = keras.Input(shape = input_shape, name = 'input')\n",
    "    y = layers.Flatten()(inp)\n",
    "    for i in range(5):\n",
    "        y = layers.Dense(width, activation = None, name = f'dense_{i+1}')(y)\n",
    "        y = layers.BatchNormalization(name = f'bn_{i+1}')(y)\n",
    "        y = layers.Activation(tf.nn.relu, name = f'act_{i+1}')(y)\n",
    "        \n",
    "    y = layers.Dense(num_classes, activation = 'softmax', name = 'classifier_head')(y)\n",
    "    \n",
    "    return keras.Model(inputs = inp, outputs = y, name = 'dense_nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vgg_nn(input_shape, num_classes = 10):\n",
    "    print(f\"Received `num_classes` = {num_classes}\")\n",
    "    inp = keras.Input(shape = input_shape, name = 'input')\n",
    "    vgg_op = keras.applications.VGG16(\n",
    "                                        include_top = False,\n",
    "                                        weights = 'imagenet',\n",
    "                                        input_tensor = None,\n",
    "                                        input_shape = input_shape,\n",
    "                                        pooling = \"avg\",\n",
    "                                     )(inp)\n",
    "    \n",
    "    y = layers.Dense(num_classes, activation = 'softmax', name = 'classifier_head')(vgg_op)\n",
    "    model = keras.Model(inputs = inp, outputs = y, name = 'vgg')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minimum_loss(nn, loss_fn, train_data, metrics = None, batch_size = 32, num_epochs = 10):\n",
    "    '''\n",
    "    Trains the Neural Network specified by `nn` using Adam and finds minimum loss\n",
    "    \n",
    "    Arguments:\n",
    "    -----------\n",
    "        - nn: The neural network to train\n",
    "        - loss_fn: The loss function to minimize.\n",
    "        - train_data: A Tuple (X_train, y_train) where both X_train and y_train are numpy.ndarrays\n",
    "                        -- X_train specifies the set of examples\n",
    "                        -- y_train specifies the labels\n",
    "        - metrics: Additional metrics to monitor (such as accuracy)\n",
    "        - batch_size: batch size during training\n",
    "        - num_epochs: Number of epochs to train\n",
    "    \n",
    "    Returns:\n",
    "    ---------\n",
    "    - The minimum loss\n",
    "    - The list of loss values for every batch\n",
    "    '''\n",
    "    \n",
    "    nn.compile(optimizer = 'sgd', loss = loss_fn, metrics = metrics)\n",
    "    X_train, y_train = train_data\n",
    "    assert isinstance(X_train, np.ndarray), f\"X_train must be a numpy array. Found {type(X_train)}\"\n",
    "    assert isinstance(y_train, np.ndarray), f\"y_train must be a numpy array. Found {type(y_train)}\"\n",
    "    assert X_train.shape[0] == y_train.shape[0], f\"X_train and y_train must have same batch dimensions. Found X_train.shape: {X_train.shape} and y_train.shape: {y_train.shape}\"\n",
    "    \n",
    "    num_batches = np.ceil(X_train.shape[0] / batch_size).astype(np.int32)\n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "        pbar = trange(num_batches)\n",
    "        for batch_idx in range(num_batches):\n",
    "            start = batch_idx * batch_size\n",
    "            end = (batch_idx + 1) * batch_size\n",
    "            X_batch, y_batch = X_train[start:end], y_train[start:end]\n",
    "            X_batch = tf.convert_to_tensor(X_batch, dtype = tf.float32)\n",
    "            y_batch = tf.convert_to_tensor(y_batch, dtype = tf.float32)\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = nn(X_batch, training = True)\n",
    "                loss = nn.compiled_loss(y_batch, y_pred)\n",
    "            grads = tape.gradient(loss, nn.trainable_variables)\n",
    "            nn.optimizer.apply_gradients(zip(grads, nn.trainable_variables))\n",
    "            nn.compiled_metrics.update_state(y_batch, y_pred)\n",
    "            metric_values = [f\"{m.name}: {m.result().numpy():.4f}\" for m in nn.metrics]\n",
    "            message = \" - \".join(metric_values)\n",
    "            \n",
    "            loss_history.append(nn.metrics[0].result().numpy())\n",
    "            \n",
    "            pbar.set_postfix_str(message)\n",
    "            pbar.update(1)\n",
    "            \n",
    "        pbar.close()\n",
    "    \n",
    "    loss_history = np.asarray(loss_history)\n",
    "    min_loss = loss_history.min()\n",
    "    \n",
    "    return min_loss, loss_history      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(\n",
    "                nn, \n",
    "                optimizer, \n",
    "                loss_fn, \n",
    "                train_data, \n",
    "                metrics = None, \n",
    "                batch_size = 32, \n",
    "                num_epochs = 10, \n",
    "                L_smoothness_iterations = 30,\n",
    "                num_trace_vectors = 10\n",
    "            ):\n",
    "    \"\"\"\n",
    "    Trains the neural network and estimates both:\n",
    "      (1) The L-smoothness constant (largest Hessian eigenvalue \n",
    "          w.r.t. model parameters) via power iteration\n",
    "      (2) The Hessian trace via Hutchinson's method\n",
    "    in the same training loop (so no separate pass is needed).\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    nn : tf.keras.Model\n",
    "    optimizer : tf.keras.optimizers.Optimizer\n",
    "    loss_fn : Callable like tf.keras.losses.*\n",
    "    train_data : (X_train, y_train) as numpy arrays\n",
    "    metrics : list of Keras metrics or None\n",
    "    batch_size : int\n",
    "    num_epochs : int\n",
    "    num_trace_vectors : number of random vectors for Hutchinson's trace estimator\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    loss_values : list of float\n",
    "        Loss at each iteration\n",
    "    gradient_norms : list of float\n",
    "        Grad-norm at each iteration\n",
    "    trace_vals_hessian : list of float\n",
    "        Estimated Hessian trace per iteration\n",
    "    learning_rate_schedule : list of float\n",
    "        Learning rate history\n",
    "    \"\"\"\n",
    "    \n",
    "    nn.compile(optimizer = optimizer, loss = loss_fn, metrics = metrics)\n",
    "    X_train, y_train = train_data\n",
    "    assert isinstance(X_train, np.ndarray), f\"X_train must be a numpy array. Found {type(X_train)}\"\n",
    "    assert isinstance(y_train, np.ndarray), f\"y_train must be a numpy array. Found {type(y_train)}\"\n",
    "    \n",
    "    gradient_norms = []\n",
    "    loss_values = []\n",
    "    trace_vals_hessian = []\n",
    "    learning_rate_schedule = []\n",
    "    \n",
    "    num_samples = X_train.shape[0]\n",
    "    num_batches = int(np.ceil(num_samples / batch_size))\n",
    "    \n",
    "    iteration = 0\n",
    "    max_iters = num_batches * num_epochs\n",
    "    eta0 = optimizer.learning_rate.numpy()\n",
    "    \n",
    "    learning_rate_schedule.append(eta0)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            # ------------------ Get the current mini-batch ------------------\n",
    "            start = batch_idx * batch_size\n",
    "            end = min((batch_idx + 1) * batch_size, num_samples)\n",
    "            X_batch, y_batch = X_train[start:end], y_train[start:end]\n",
    "            \n",
    "            # ------------------ 1) Forward + Backward pass (training) ------------------\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = nn(X_batch, training = True)\n",
    "                loss = loss_fn(y_batch, y_pred)\n",
    "            grads = tape.gradient(loss, nn.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, nn.trainable_variables))\n",
    "            \n",
    "            grad_norm = tf.linalg.global_norm(grads)\n",
    "            \n",
    "            # ------------------ 3) Estimate Hessian trace (Hutchinson's method) ------------------\n",
    "            #\n",
    "            # We do num_trace_vectors random vectors z (default = 10).\n",
    "            # For each z: compute z^T (H z) using the double-gradient approach.\n",
    "            # Then average them.\n",
    "            trace_vals = []\n",
    "            for _ in range(num_trace_vectors):\n",
    "                # Sample a random vector z matching shapes of each parameter\n",
    "                z_list = [tf.random.normal(tf.shape(var)) for var in nn.trainable_variables]\n",
    "                \n",
    "                # double-backprop to get z^T H z\n",
    "                with tf.GradientTape() as tape2:\n",
    "                    with tf.GradientTape() as tape1:\n",
    "                        y_pred_inner = nn(X_batch, training = True)\n",
    "                        loss_inner = loss_fn(y_batch, y_pred_inner)\n",
    "                    grads_inner = tape1.gradient(loss_inner, nn.trainable_variables)\n",
    "                    \n",
    "                    directional_deriv_z = tf.add_n([tf.reduce_sum(g * z) for g, z in zip(grads_inner, z_list)])\n",
    "                \n",
    "                hvp_z = tape2.gradient(directional_deriv_z, nn.trainable_variables)\n",
    "                hvp_z = [\n",
    "                            tf.zeros_like(vv) if (hvp_zi is None) else hvp_zi\n",
    "                            for vv, hvp_zi in zip(nn.trainable_variables, hvp_z)\n",
    "                        ]\n",
    "                \n",
    "                # z^T (H z)\n",
    "                zHz = tf.add_n([\n",
    "                                    tf.reduce_sum(z * h) for z, h in zip(z_list, hvp_z)\n",
    "                               ])\n",
    "                trace_vals.append(zHz)\n",
    "            \n",
    "            # Take the average as the trace estimate\n",
    "            trace_estimate = tf.reduce_max(trace_vals).numpy()\n",
    "            \n",
    "            # ------------------ Book-keeping & Logs ------------------\n",
    "            gradient_norms.append(grad_norm.numpy())\n",
    "            loss_values.append(loss.numpy())\n",
    "            trace_vals_hessian.append(trace_estimate)\n",
    "            \n",
    "            iteration += 1\n",
    "            \n",
    "            # LR decay after some fraction of training\n",
    "            if iteration >= int(0.7 * max_iters):\n",
    "                new_lr = eta0 * np.exp(-0.01 * iteration)\n",
    "                optimizer.learning_rate.assign(new_lr)\n",
    "                learning_rate_schedule.append(new_lr)\n",
    "            else:\n",
    "                learning_rate_schedule.append(eta0)\n",
    "            \n",
    "            print(\n",
    "                    f\" Batch {batch_idx + 1}/{num_batches}: \"\n",
    "                    f\"LR = {optimizer.learning_rate.numpy():.5f}, \"\n",
    "                    f\"Loss = {loss.numpy():.4f}, \"\n",
    "                    f\"||Grad|| = {grad_norm.numpy():.4f}, \"\n",
    "                    f\"Trace(H) ~ {trace_estimate:.4f}\"\n",
    "                 )\n",
    "            \n",
    "    return loss_values, gradient_norms, trace_vals_hessian, learning_rate_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_L_smoothness_constant(\n",
    "    nn, \n",
    "    optimizer, \n",
    "    loss_fn, \n",
    "    train_data, \n",
    "    metrics = None, \n",
    "    batch_size = 32, \n",
    "    num_epochs = 10, \n",
    "    L_smoothness_iterations = 30\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains the neural network and estimates both:\n",
    "      (1) The L-smoothness constant (largest Hessian eigenvalue \n",
    "          w.r.t. model parameters) via power iteration\n",
    "      (2) The Hessian trace via Hutchinson's method\n",
    "    in the same training loop (so no separate pass is needed).\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    nn : tf.keras.Model\n",
    "    optimizer : tf.keras.optimizers.Optimizer\n",
    "    loss_fn : Callable like tf.keras.losses.*\n",
    "    train_data : (X_train, y_train) as numpy arrays\n",
    "    metrics : list of Keras metrics or None\n",
    "    batch_size : int\n",
    "    num_epochs : int\n",
    "    L_smoothness_iterations : number of power iterations to estimate top eigenvalue\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    loss_values : list of float\n",
    "        Loss at each iteration\n",
    "    gradient_norms : list of float\n",
    "        Grad-norm at each iteration\n",
    "    eig_vals_hessian : list of float\n",
    "        Estimated largest Hessian eigenvalue per iteration\n",
    "    learning_rate_schedule : list of float\n",
    "        Learning rate history\n",
    "    \"\"\"\n",
    "    \n",
    "    nn.compile(optimizer = optimizer, loss = loss_fn, metrics = metrics)\n",
    "    X_train, y_train = train_data\n",
    "    assert isinstance(X_train, np.ndarray), f\"X_train must be a numpy array. Found {type(X_train)}\"\n",
    "    assert isinstance(y_train, np.ndarray), f\"y_train must be a numpy array. Found {type(y_train)}\"\n",
    "    \n",
    "    gradient_norms = []\n",
    "    loss_values = []\n",
    "    eig_vals_hessian = []\n",
    "    learning_rate_schedule = []\n",
    "    \n",
    "    num_samples = X_train.shape[0]\n",
    "    num_batches = int(np.ceil(num_samples / batch_size))\n",
    "    \n",
    "    iteration = 0\n",
    "    max_iters = num_batches * num_epochs\n",
    "    eta0 = optimizer.learning_rate.numpy()\n",
    "    \n",
    "    learning_rate_schedule.append(eta0)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            # ------------------ Get the current mini-batch ------------------\n",
    "            start = batch_idx * batch_size\n",
    "            end = min((batch_idx + 1) * batch_size, num_samples)\n",
    "            X_batch, y_batch = X_train[start:end], y_train[start:end]\n",
    "            \n",
    "            # ------------------ 1) Forward + Backward pass (training) ------------------\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = nn(X_batch, training = True)\n",
    "                loss = loss_fn(y_batch, y_pred)\n",
    "            grads = tape.gradient(loss, nn.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, nn.trainable_variables))\n",
    "            \n",
    "            grad_norm = tf.linalg.global_norm(grads)\n",
    "            \n",
    "            # ------------------ 2) Estimate largest Hessian eigenvalue (Power Iteration) ------------------\n",
    "            \n",
    "            # Initialize v as random, shape-matching each parameter\n",
    "            v = [tf.random.normal(tf.shape(var)) for var in nn.trainable_variables]\n",
    "            norm_v = tf.linalg.global_norm(v)\n",
    "            if norm_v > 0:\n",
    "                v = [vi / norm_v for vi in v]  # normalize\n",
    "            \n",
    "            # Repeatedly compute Hv and normalize\n",
    "            for _ in range(L_smoothness_iterations):\n",
    "                # directional derivative v^T grad(loss)\n",
    "                with tf.GradientTape() as tape2:\n",
    "                    with tf.GradientTape() as tape1_inner:\n",
    "                        y_pred_inner = nn(X_batch, training = True)\n",
    "                        loss_inner = loss_fn(y_batch, y_pred_inner)\n",
    "                    grads_inner = tape1_inner.gradient(loss_inner, nn.trainable_variables)\n",
    "                    directional_deriv = tf.add_n([\n",
    "                        tf.reduce_sum(g * vi) for g, vi in zip(grads_inner, v)\n",
    "                    ])\n",
    "                hv = tape2.gradient(directional_deriv, nn.trainable_variables)\n",
    "                hv = [tf.zeros_like(var) if h is None else h \n",
    "                      for var, h in zip(nn.trainable_variables, hv)]\n",
    "                norm_hv = tf.linalg.global_norm(hv)\n",
    "                if norm_hv == 0:\n",
    "                    break\n",
    "                v = [h / norm_hv for h in hv]\n",
    "            \n",
    "            # Final Rayleigh quotient: v^T (H v)\n",
    "            with tf.GradientTape() as tape2:\n",
    "                with tf.GradientTape() as tape1_inner:\n",
    "                    y_pred_inner = nn(X_batch, training=True)\n",
    "                    loss_inner = loss_fn(y_batch, y_pred_inner)\n",
    "                grads_inner = tape1_inner.gradient(loss_inner, nn.trainable_variables)\n",
    "                directional_deriv = tf.add_n([\n",
    "                    tf.reduce_sum(g * vi) for g, vi in zip(grads_inner, v)\n",
    "                ])\n",
    "            hv = tape2.gradient(directional_deriv, nn.trainable_variables)\n",
    "            hv = [tf.zeros_like(var) if h is None else h \n",
    "                  for var, h in zip(nn.trainable_variables, hv)]\n",
    "            eigen_estimate = tf.add_n([\n",
    "                tf.reduce_sum(vi * hi) for vi, hi in zip(v, hv)\n",
    "            ])\n",
    "            largest_eig_val = abs(eigen_estimate.numpy())\n",
    "            \n",
    "            # ------------------ Book-keeping & Logs ------------------\n",
    "            gradient_norms.append(grad_norm.numpy())\n",
    "            loss_values.append(loss.numpy())\n",
    "            eig_vals_hessian.append(largest_eig_val)\n",
    "            \n",
    "            iteration += 1\n",
    "            \n",
    "            # (Optional) simple LR decay after some fraction of training\n",
    "            if iteration >= int(0.7 * max_iters):\n",
    "                new_lr = eta0 * np.exp(-0.01 * iteration)\n",
    "                optimizer.learning_rate.assign(new_lr)\n",
    "                learning_rate_schedule.append(new_lr)\n",
    "            else:\n",
    "                learning_rate_schedule.append(eta0)\n",
    "            \n",
    "            print(\n",
    "                f\" Batch {batch_idx + 1}/{num_batches}: \"\n",
    "                f\"LR = {optimizer.learning_rate.numpy():.5f}, \"\n",
    "                f\"Loss = {loss.numpy():.4f}, \"\n",
    "                f\"||Grad|| = {grad_norm.numpy():.4f}, \"\n",
    "                f\"L-smoothness-constant ~ {largest_eig_val:.4f}, \"\n",
    "            )\n",
    "            \n",
    "    return loss_values, gradient_norms, eig_vals_hessian, learning_rate_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_minimum_L_smoothness_constant(nn_type = 'dense',\n",
    "                                           data = 'cifar10',\n",
    "                                           optimizer_init_learning_rate = 0.01,\n",
    "                                           optimizer_momentum = 0.99,\n",
    "                                           L_estimator_iterations = 30,\n",
    "                                           batch_size = 1024,\n",
    "                                           num_epochs = 20):\n",
    "    if data == 'cifar10':\n",
    "        (X_train, y_train), _ = obtain_cifar10()\n",
    "    elif data == 'cifar100':\n",
    "        (X_train, y_train), _ = obtain_cifar100()\n",
    "    else:\n",
    "        raise ValueError(f\"`data` argument must be either 'cifar10' or 'cifar100'. Found {data}\")\n",
    "    \n",
    "    if nn_type == 'dense':\n",
    "        nn = create_dense_nn(input_shape = X_train.shape[1:], width = 1024, num_classes = y_train.shape[1])\n",
    "    elif nn_type == 'vgg':\n",
    "        nn = create_vgg_nn(input_shape = X_train.shape[1:], num_classes = y_train.shape[1])\n",
    "    else:\n",
    "        raise ValueError(f\"`nn_type` argument must be either 'dense' or 'vgg'. Found {nn_type}\")\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate = optimizer_init_learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits = False, name = 'loss')\n",
    "    losses, grad_norms, eig_vals_hessian, learning_rate_schedule = find_min_L_smoothness_constant(nn, optimizer, loss, \n",
    "                                                                                                  train_data = (X_train, y_train),\n",
    "                                                                                                  batch_size = batch_size, num_epochs = num_epochs,\n",
    "                                                                                                  L_smoothness_iterations = L_estimator_iterations)\n",
    "    eig_vals_hessian = np.asarray(eig_vals_hessian)\n",
    "    losses = np.asarray(losses)\n",
    "    grad_norms = np.asarray(grad_norms)\n",
    "    learning_rate_schedule = np.asarray(learning_rate_schedule)\n",
    "    \n",
    "    print(f\"Estimated Minimum L-smoothness constant: {eig_vals_hessian.min():.4f}\")\n",
    "    \n",
    "    return eig_vals_hessian.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pl_constant(nn_type = 'dense',\n",
    "                         data = 'cifar10',\n",
    "                         batch_size = 4096,\n",
    "                         optimizer_init_learning_rate = 1e-4,\n",
    "                         num_epochs = 20,\n",
    "                         burnin_steps = 0,\n",
    "                         min_loss_gap = 0.05,\n",
    "                         display_ncols = 50):\n",
    "    \n",
    "    if data == 'cifar10':\n",
    "        (X_train, y_train), _ = obtain_cifar10()\n",
    "    elif data == 'cifar100':\n",
    "        (X_train, y_train), _ = obtain_cifar100()\n",
    "    else:\n",
    "        raise ValueError(f\"`data` argument must be either 'cifar10' or 'cifar100'. Found {data}\")\n",
    "    \n",
    "    if nn_type == 'dense':\n",
    "        nn = create_dense_nn(input_shape = X_train.shape[1:], width = 1024, num_classes = y_train.shape[1])\n",
    "    elif nn_type == 'vgg':\n",
    "        nn = create_vgg_nn(input_shape = X_train.shape[1:], num_classes = y_train.shape[1])\n",
    "    else:\n",
    "        raise ValueError(f\"`nn_type` argument must be either 'dense' or 'vgg'. Found {nn_type}\")\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate = optimizer_init_learning_rate)\n",
    "    loss_fn = keras.losses.CategoricalCrossentropy(from_logits = False, name = 'loss')\n",
    "    \n",
    "    grad_norms = []\n",
    "    losses = []\n",
    "    \n",
    "    num_samples = X_train.shape[0]\n",
    "    num_batches = int(np.ceil(num_samples / batch_size))\n",
    "    \n",
    "    iteration = 0\n",
    "        \n",
    "    for i in range(1, num_epochs + 1):\n",
    "        print(f\"Epoch {i:03d}/{num_epochs:03d}\")\n",
    "                \n",
    "        idx = np.random.permutation(num_samples)\n",
    "        X_train, y_train = X_train[idx], y_train[idx]\n",
    "        \n",
    "        pbar = trange(num_batches, ncols = display_ncols, ascii = '.>=')        \n",
    "        for batch_idx in range(num_batches):            \n",
    "            iteration += 1\n",
    "            start = batch_idx * batch_size\n",
    "            end = min((batch_idx + 1) * batch_size, num_samples)\n",
    "            X_batch, y_batch = X_train[start:end], y_train[start:end]\n",
    "            \n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = nn(X_batch, training = True)\n",
    "                loss = loss_fn(y_batch, y_pred)\n",
    "            \n",
    "            grads = tape.gradient(loss, nn.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, nn.trainable_variables))\n",
    "\n",
    "            grad_norms.append(tf.linalg.global_norm(grads).numpy())\n",
    "            losses.append(loss.numpy())\n",
    "            \n",
    "            pbar.set_postfix_str(f'step: {iteration} - loss: {loss.numpy():4f}')\n",
    "            pbar.update(1)\n",
    "        \n",
    "        pbar.close()\n",
    "\n",
    "    losses = np.asarray(losses, dtype = np.float64)\n",
    "    grad_norms_sq = np.asarray(grad_norms, dtype = np.float64) ** 2\n",
    "    \n",
    "    if burnin_steps > 0:\n",
    "        losses = losses[burnin_steps:]\n",
    "        grad_norms_sq = grad_norms_sq[burnin_steps:]\n",
    "\n",
    "    # --- no-intercept fit ---\n",
    "    f_star = float(np.min(losses))\n",
    "\n",
    "    x = np.maximum(losses - f_star, 0.0)\n",
    "    \n",
    "    mask = x > min_loss_gap\n",
    "    if np.any(mask):\n",
    "        x = x[mask]\n",
    "        losses = losses[mask]\n",
    "        grad_norms_sq = grad_norms_sq[mask]    \n",
    "    \n",
    "    ratios = grad_norms_sq / (2.0 * np.maximum(x, 1e-12))  # each gives an admissible μ\n",
    "    mu_estimate = float(np.min(ratios))\n",
    "\n",
    "    print(f\"Estimated PL-constant (mu): {mu_estimate:.6f}  ;  f*: {f_star:.6f}\")\n",
    "\n",
    "    # --- visualization ---\n",
    "    # y = grad_norms_sq\n",
    "    # fig, ax = plt.subplots(1, 1, figsize = (8, 8))\n",
    "    # ax.scatter(x, y, s = 10, label = 'observations')\n",
    "    # # line through origin in (x, y): y_hat = slope * x\n",
    "    # xs = np.linspace(0.0, float(x.max()), 200)\n",
    "    # ax.plot(xs, 2.0 * mu_estimate * xs, label = r'$y=2\\mu x$', linewidth = 2)\n",
    "    # ax.set_xlabel(r'$f(\\theta)-f_\\star$', fontsize = 16)\n",
    "    # ax.set_ylabel(r'$\\|\\nabla f(\\theta)\\|^2$', fontsize = 16)\n",
    "    # ax.tick_params(axis = 'both', labelsize = 14)\n",
    "    # ax.legend()\n",
    "    # fig.tight_layout()\n",
    "\n",
    "    return mu_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_hessian_trace(nn_type = 'dense', \n",
    "                           data = 'cifar10',\n",
    "                           optimizer_init_learning_rate = 1e-4,  \n",
    "                           num_trace_vectors = 20,\n",
    "                           batch_size = 16384,\n",
    "                           num_epochs = 20):\n",
    "    \n",
    "    if data == 'cifar10':\n",
    "        (X_train, y_train), _ = obtain_cifar10()\n",
    "    elif data == 'cifar100':\n",
    "        (X_train, y_train), _ = obtain_cifar100()\n",
    "    else:\n",
    "        raise ValueError(f\"`data` argument must be either 'cifar10' or 'cifar100'. Found {data}\")\n",
    "    \n",
    "    if nn_type == 'dense':\n",
    "        nn = create_dense_nn(input_shape = X_train.shape[1:], width = 1024, num_classes = y_train.shape[1])\n",
    "    elif nn_type == 'vgg':\n",
    "        nn = create_vgg_nn(input_shape = X_train.shape[1:], num_classes = y_train.shape[1])\n",
    "    else:\n",
    "        raise ValueError(f\"`nn_type` argument must be either 'dense' or 'vgg'. Found {nn_type}\")\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate = optimizer_init_learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits = False, name = 'loss')\n",
    "    losses, grad_norms, trace_vals_hessian, learning_rate_schedule = train_nn(nn, optimizer, loss, \n",
    "                                                                              train_data = (X_train, y_train),\n",
    "                                                                              batch_size = batch_size, num_epochs = num_epochs,\n",
    "                                                                              num_trace_vectors = num_trace_vectors)\n",
    "\n",
    "    losses = np.asarray(losses)\n",
    "    trace_vals_hessian = np.asarray(trace_vals_hessian)\n",
    "    learning_rate_schedule = np.asarray(learning_rate_schedule)\n",
    "                       \n",
    "    hessian_trace_estimate = trace_vals_hessian.mean()          # Hutchinson's is unbiased only for mean **NOT** for max estimate\n",
    "    \n",
    "    print(f\"Estimated Maximum Trace of Hessian: {trace_vals_hessian.max():.4f}, Estimated Mean Trace of Hessian: {trace_vals_hessian.mean():.4f}\")\n",
    "    \n",
    "    return (None, hessian_trace_estimate), trace_vals_hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_block_ids(n, max_delay, start = 0):\n",
    "    \"\"\"\n",
    "    Vectorised block labels 0 … K-1 for every step 1 … n.\n",
    "    `start` denotes t_0 or tau_M.\n",
    "    \"\"\"\n",
    "    return tf.range(start, n, delta = 1, dtype = tf.int32) // (max_delay + 1)\n",
    "\n",
    "\n",
    "def _envelope_over_blocks(eta, block_ids, tau_M = 0, is_max = True):\n",
    "    \"\"\"\n",
    "    eta        : (N , n)\n",
    "    block_ids  : (n,)  int32 labels 0 … K-1\n",
    "    returns    : (N , K)   η_max or η_min per block\n",
    "    \"\"\"\n",
    "    eta_T = tf.transpose(eta[:, tau_M:])              # (n , N)\n",
    "    K = tf.reduce_max(block_ids) + 1                  # scalar\n",
    "    if is_max:\n",
    "        env_T = tf.math.unsorted_segment_max(eta_T, block_ids, K)\n",
    "    else:\n",
    "        env_T = tf.math.unsorted_segment_min(eta_T, block_ids, K)\n",
    "    return tf.transpose(env_T)                 # (N , K)\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#  κ(K)  of Theorem 2   (vectorised, XLA‑friendly)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "@tf.function(jit_compile = True)\n",
    "def kappa_fn_tf(eta,          # (N , n)   step sizes per trajectory\n",
    "                mu, L, sigma_sq,\n",
    "                T,            # horizon (scalar)\n",
    "                G_local,      # (N,)  or scalar broadcastable to (N ,1)\n",
    "                hess_tr,      # (N,)  trace of Hessian ‖∇²f‖₁\n",
    "                tau_M,        # t₀  (scalar)\n",
    "                block_ids,    # (n,)  int32 labels 0…K-1\n",
    "                delta_t = 1.0):\n",
    "    \"\"\"\n",
    "    Vectorised computation of κ(K) from Theorem 2 for an (N × n) batch of step\n",
    "    sequences divided into K blocks.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    kappa      : (N,)        sum over blocks\n",
    "    kappa_part : (N , K)     contribution of each block\n",
    "    \"\"\"\n",
    "    # --- common casts ---------------------------------------------------------\n",
    "    dtype = eta.dtype\n",
    "    mu, L = tf.cast(mu, dtype), tf.cast(L, dtype)\n",
    "    sigma_sq = tf.cast(sigma_sq, dtype)\n",
    "    T = tf.cast(T, dtype)\n",
    "    G_local = tf.cast(G_local, dtype)[:, None]         # (N , 1)\n",
    "    hess_tr = tf.cast(hess_tr, dtype)\n",
    "    dt = tf.cast(delta_t, dtype)\n",
    "    \n",
    "    block_ids -= tf.reduce_min(block_ids)\n",
    "\n",
    "    # --- η_max and η_min for every block --------------------------------------\n",
    "    eta_max = _envelope_over_blocks(eta, block_ids, tau_M = tau_M, is_max = True)   # (N , K)\n",
    "    eta_min = _envelope_over_blocks(eta, block_ids, tau_M = tau_M, is_max = False)  # (N , K)\n",
    "\n",
    "    # --- block lengths and start times ----------------------------------------\n",
    "    # Nj = #steps in block j  →  (K,)\n",
    "    Nj = tf.math.unsorted_segment_sum(\n",
    "                                        data = tf.ones_like(block_ids, dtype=tf.int32),\n",
    "                                        segment_ids = block_ids,\n",
    "                                        num_segments = tf.reduce_max(block_ids) + 1\n",
    "                                     )\n",
    "\n",
    "    Nj_dt  = tf.cast(Nj, dtype) * dt                      # (K,)\n",
    "    d      = tf.expand_dims(Nj_dt, 0)                     # (1 , K)  for broadcast\n",
    "\n",
    "    # start_times_j = Σ_{ℓ<j} Nℓ·dt  →  (K,)\n",
    "    start_times = tf.cumsum(Nj_dt, exclusive = True)\n",
    "    start_times = tf.expand_dims(start_times, 0)         # (1 , K) broadcast\n",
    "\n",
    "    # --- log-prefactor ---------------------------------------------------------\n",
    "    log_pref = -mu * eta_max * tau_M - tf.math.log(mu * eta_max)\n",
    "\n",
    "    # --- stable log(exp(a) − exp(b)) ------------------------------------------\n",
    "    a =  mu * (eta_max - eta_min) * d          # (N , K)\n",
    "    b = -mu *  eta_min * d                     # (N , K)\n",
    "    m = tf.minimum(a, b)\n",
    "    M = tf.maximum(a, b)\n",
    "    log_diff_inner = M + tf.math.log1p(-tf.exp(m - M))\n",
    "\n",
    "    # complete difference term (add μη_max·t_j)\n",
    "    log_diff = mu * eta_max * start_times + log_diff_inner\n",
    "\n",
    "    # --- constant term inside the bracket -------------------------------------\n",
    "    term1 = 0.5 * L**2 * eta_max**3 * (T**2 * G_local**2 + sigma_sq * T)\n",
    "    term2 = 0.5 * sigma_sq * eta_max**2 * hess_tr\n",
    "    log_const = tf.math.log(term1 + term2)\n",
    "\n",
    "    # --- assemble and reduce ---------------------------------------------------\n",
    "    log_kappa_part = log_pref + log_diff + log_const      # (N , K)\n",
    "    kappa_part = tf.exp(log_kappa_part)                   # (N , K)\n",
    "    kappa = tf.reduce_sum(kappa_part, axis=1)             # (N ,)\n",
    "\n",
    "    return kappa, kappa_part\n",
    "\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#  log‑bound and objective\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "@tf.function(jit_compile = True)\n",
    "def log_bound_batched_tf(eta_mat, f0_batch, mu, kappa):\n",
    "    Sn = tf.reduce_sum(eta_mat, axis = 1)\n",
    "    term1 = tf.math.log(f0_batch) - mu * Sn\n",
    "    term2 = tf.math.log(kappa)\n",
    "    return tf.maximum(term1, term2) + tf.math.log1p(tf.exp(-tf.abs(term1 - term2)))\n",
    "\n",
    "\n",
    "@tf.function(jit_compile = True)\n",
    "def objective_log_bound_squared_batched_tf(eta_mat, f0_batch, mu, kappa):\n",
    "    log_b = log_bound_batched_tf(eta_mat, f0_batch, mu, kappa)\n",
    "    two_log_b = 2.0 * log_b\n",
    "    max_l = tf.reduce_max(two_log_b)\n",
    "    return tf.exp(tf.math.log(tf.reduce_sum(tf.exp(two_log_b - max_l))) + max_l)\n",
    "\n",
    "def eta_fn(suboptimality_gap, k, mu, L, sigma_sq, G_local, T, H_max = None, clip_factor = 0.1):\n",
    "    '''\n",
    "        Fixes learning rate to `clip_factor` of the prescribed upper-bound from Theorem 2.\n",
    "            - suboptimality_gap: Shape: (num_initializations, )\n",
    "            - k                : int\n",
    "            - L                : float\n",
    "            - sigma_sq         : float\n",
    "            - G_local          : float\n",
    "            - T                : int\n",
    "            - clip_factor      : fraction of upper-bound to clip the learning rate to\n",
    "        \n",
    "        Returns:\n",
    "            - scalar learning rate of shape ()\n",
    "    '''   \n",
    "    Vt = tf.reduce_mean(suboptimality_gap)\n",
    "    H_max = k * L if H_max is None else H_max\n",
    "    a = L**2 * T**2 * G_local**2 + L**2 * sigma_sq * T\n",
    "    \n",
    "    eta_hi = (-sigma_sq * H_max + tf.math.sqrt(sigma_sq**2 * H_max**2 + 16 * mu * Vt * a)) / (2 * a)\n",
    "        \n",
    "    return clip_factor * eta_hi\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def discrete_time_pl_bound_fast_tf(f0, kappa, mu, eta, tau_M = 0):\n",
    "    '''\n",
    "    Returns a tensor 'bounds' of length N+1\n",
    "\n",
    "    We do a stable summation of exp(...) to avoid overflow, and we allow\n",
    "    e^{- mu sum(eta)} to underflow to 0 if the sum is huge (which is usually safe).\n",
    "\n",
    "    Arguments\n",
    "    ----------\n",
    "    f0         : float\n",
    "                 f(theta(0)) - f(theta^*)\n",
    "    kappa      : float\n",
    "                 noise-term constant from the PL bound. Shape (n, )\n",
    "    mu         : float\n",
    "                 the PL (Polyak-Łojasiewicz) constant\n",
    "    eta        : tf.Tensor or np.ndarray of shape (n, )\n",
    "                 the discrete step sizes. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bounds : tf.Tensor of shape (n+1,)\n",
    "             The bound at each iteration n=0..n, inclusive.\n",
    "             bounds[0] = f0, and bounds[k] for k>0 is the bound after k steps.\n",
    "    '''\n",
    "    # Convert eta to a TensorFlow tensor with float32 precision.\n",
    "    eta = tf.convert_to_tensor(eta, dtype = tf.float32)[tau_M:]\n",
    "    \n",
    "    # Compute the cumulative sum of the step sizes.\n",
    "    cumsum_eta = tf.math.cumsum(eta)  # shape: (n,)\n",
    "    \n",
    "    # For n = 1,...,n, compute the bound:\n",
    "    # f0 * exp(-mu * (sum of eta over the k steps)) + kappa.\n",
    "    bounds_without_initial = f0 * tf.exp(- mu * cumsum_eta) + kappa  # shape: (n,)\n",
    "    \n",
    "    # Prepend the initial f0 value.\n",
    "    f0_tensor = tf.reshape(tf.convert_to_tensor(f0, dtype = tf.float32), [1])\n",
    "    bounds = tf.concat([f0_tensor, bounds_without_initial], axis = 0)  # shape: (n+1,)\n",
    "    \n",
    "    return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_objective(nn, loss_fn, X, y, batch_size = 4096):\n",
    "    if batch_size <= 0:\n",
    "        num_batches = 1\n",
    "        batch_size = X.shape[0]\n",
    "    else:\n",
    "        num_batches = np.ceil(X.shape[0] / batch_size).astype(np.int32)\n",
    "    losses = []\n",
    "    for batch_idx in range(num_batches):\n",
    "        y_pred = nn(X[batch_idx * batch_size: (batch_idx + 1) * batch_size], training = False)\n",
    "        loss_batch = call_loss(loss_fn, y[batch_idx * batch_size: (batch_idx + 1) * batch_size], y_pred)\n",
    "        losses.append(loss_batch)\n",
    "    \n",
    "    return tf.reduce_mean(losses)\n",
    "\n",
    "def call_loss(loss_fn, y_true, y_pred):\n",
    "    # Respect the loss's own reduction\n",
    "    red = getattr(loss_fn, \"reduction\", None)\n",
    "    if red in (tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE,\n",
    "               tf.keras.losses.Reduction.AUTO,\n",
    "               None):\n",
    "        return loss_fn(y_true, y_pred)            # already averaged\n",
    "    elif red == tf.keras.losses.Reduction.NONE:\n",
    "        return tf.reduce_mean(loss_fn(y_true, y_pred))\n",
    "    elif red == tf.keras.losses.Reduction.SUM:\n",
    "        # normalize to mean for comparable scale\n",
    "        vals = loss_fn(y_true, y_pred)\n",
    "        return vals / tf.cast(tf.shape(y_true)[0], vals.dtype)\n",
    "    else:\n",
    "        return loss_fn(y_true, y_pred)\n",
    "\n",
    "\n",
    "def evaluate_gradient(nn, loss_fn, X, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = nn(X, training = False)\n",
    "        loss_batch = call_loss(loss_fn, y, y_pred)\n",
    "    gradient = tape.gradient(loss_batch, nn.trainable_variables)\n",
    "    \n",
    "    return gradient, loss_batch\n",
    "\n",
    "\n",
    "def clone_with_weights(base):\n",
    "    new = keras.models.clone_model(base)\n",
    "    new.build(base.input_shape)\n",
    "    new.set_weights(base.get_weights())\n",
    "    return new\n",
    "\n",
    "def grad_and_sq_microbatch(model, loss_fn, Xb, yb, vars_list = None, chunks = 8):\n",
    "    if vars_list is None:\n",
    "        vars_list = model.trainable_variables\n",
    "    n = int(Xb.shape[0])\n",
    "    m = max(1, min(int(chunks), n))\n",
    "    base = n // m\n",
    "    sizes = [base]*(m-1) + [n - base*(m-1)]\n",
    "    Xs = tf.split(Xb, sizes, axis = 0)\n",
    "    ys = tf.split(yb, sizes, axis = 0)\n",
    "\n",
    "    grads_lists = [[] for _ in vars_list]\n",
    "    bsizes = []\n",
    "\n",
    "    for Xc, yc in zip(Xs, ys):\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = model(Xc, training = True)\n",
    "            loss  = call_loss(loss_fn, yc, preds)  # see §4 below\n",
    "        gc = tape.gradient(loss, vars_list)\n",
    "        for i, (g, v) in enumerate(zip(gc, vars_list)):\n",
    "            if g is None: g = tf.zeros_like(v)\n",
    "            grads_lists[i].append(g)\n",
    "        bsizes.append(int(Xc.shape[0]))\n",
    "\n",
    "    # mean grad over whole batch\n",
    "    g_mean_list = [tf.reduce_mean(tf.stack(gs, axis = 0), axis = 0) for gs in grads_lists]\n",
    "\n",
    "    # mean of per-example squared grads: (1/N) * sum_j b_j * (g_mean_j)^2\n",
    "    N = float(n)\n",
    "    g2_mean_list = []\n",
    "    for gs in grads_lists:\n",
    "        g_means = tf.stack(gs, axis = 0)  # [m, ...]\n",
    "        b = tf.constant(bsizes, dtype=g_means.dtype)\n",
    "        b = tf.reshape(b, [tf.shape(g_means)[0]] + [1] * (len(g_means.shape) - 1))\n",
    "        g2_mean = tf.reduce_sum(b * tf.square(g_means), axis = 0) / N\n",
    "        g2_mean_list.append(g2_mean)\n",
    "    return g_mean_list, g2_mean_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asgd(\n",
    "            nn,\n",
    "            mu,\n",
    "            L,\n",
    "            hessian_trace,\n",
    "            max_delay,\n",
    "            sigma_sq,\n",
    "            iterations = 1000,\n",
    "            eta_init_schedule = None,\n",
    "            dc_asgd_schedule = None,\n",
    "            M_frac = None,\n",
    "            dynamic_lr = True,\n",
    "            clip_factor = 0.9,\n",
    "            clip_value = None,\n",
    "            enable_dcasgd = True,\n",
    "            enable_sgd = True,\n",
    "            dcasgd_alpha = 0.05,\n",
    "            dcasgd_beta = 0.999,\n",
    "            clip_delta_norm = None,\n",
    "            clip_v_value = None,\n",
    "            **kwargs\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Simulates Asynchronous SGD (A-SGD) on a neural network objective, with possible gradient delays/loss.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nn : tf.keras.Model\n",
    "        The neural network as the objective.\n",
    "    mu : float\n",
    "        Strong-convexity or related parameter (if used).\n",
    "    L : float\n",
    "        Lipschitz constant (or an upper bound on gradient norms).\n",
    "    hessian_trace : float\n",
    "        Trace of the Hessian (if relevant to your schedule).\n",
    "    max_delay : int\n",
    "        Maximum possible delay. Actual delay drawn from Unif[0, max_delay].\n",
    "    sigma_sq : float or array-like\n",
    "        Gradient noise variance or array of per-step variances.\n",
    "    iterations : int\n",
    "        Number of training iterations.\n",
    "    eta_schedule : callable or None\n",
    "        If provided, a function that takes `iterations` and returns an array-like of LRs.\n",
    "    \n",
    "    Additional Keyword Args\n",
    "    -----------------------\n",
    "    train_data : tuple (X, y)\n",
    "        Required for training. X and y are np.ndarrays or tf.Tensors of data and labels.\n",
    "    loss_fn : tf.keras.losses.Loss\n",
    "        The loss criterion. Required.\n",
    "    batch_size : int, default = 4096\n",
    "        Batch size for mini-batch gradient computations.\n",
    "    apply_momentum: bool, default = False\n",
    "        If True then apply momentum to SGD.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trajectory_f_async : list of floats\n",
    "        The loss at each iteration (measured on the mini-batch used that step).\n",
    "    eta_used : np.ndarray\n",
    "        The array of learning rates used at each iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    train_data = kwargs.pop('train_data', None)\n",
    "    loss_fn = kwargs.pop('loss_fn', None)\n",
    "    batch_size = kwargs.pop('batch_size', 4096)\n",
    "    apply_momentum = kwargs.pop('apply_momentum', False)\n",
    "    nesterov_momentum = kwargs.pop('nesterov_momentum', False)\n",
    "    apply_dc_momentum = kwargs.pop('apply_dc_momentum', False)\n",
    "    \n",
    "    print(f\"A-SGD batch size: {batch_size}\")\n",
    "\n",
    "    if train_data is None:\n",
    "        raise ValueError(\"Expected train_data=(X, y). Found None.\")\n",
    "    X, y = train_data\n",
    "\n",
    "    if loss_fn is None:\n",
    "        raise ValueError(\"Expected a loss function. Found None.\")\n",
    "    \n",
    "    if eta_init_schedule is None:\n",
    "        raise ValueError(f\"eta_init_schedule must be provided\")\n",
    "    \n",
    "    if dc_asgd_schedule is None:\n",
    "        raise ValueError(f\"dc_asgd_schedule must be provided\")\n",
    "\n",
    "    if not isinstance(M_frac, Iterable):\n",
    "        M_frac = [M_frac]\n",
    "    \n",
    "    M_frac = np.asarray(M_frac).astype(np.float32)\n",
    "    M_frac_sorted = np.sort(np.asarray(M_frac).astype(np.float32))[::-1]\n",
    "    \n",
    "    if not np.array_equal(M_frac, M_frac_sorted):\n",
    "        raise ValueError(f\"If providing an iterable for M_frac, ensure it is sorted in descending order.\")\n",
    "    \n",
    "    del M_frac_sorted\n",
    "    \n",
    "    sigma_arr = tf.fill(dims = (iterations,), value = sigma_sq)\n",
    "\n",
    "    num_samples = X.shape[0]\n",
    "    num_batches = np.ceil(num_samples / batch_size)\n",
    "    k = nn.count_params()\n",
    "\n",
    "    current_batch_index = lambda k: int(k % num_batches)\n",
    "    \n",
    "    init_batch_idx = current_batch_index(0)    \n",
    "\n",
    "    X_batch_init = X[init_batch_idx * batch_size : (init_batch_idx + 1) * batch_size]\n",
    "    y_batch_init = y[init_batch_idx * batch_size : (init_batch_idx + 1) * batch_size]\n",
    "    f0_batch = evaluate_objective(nn, loss_fn, X_batch_init, y_batch_init, batch_size = batch_size).numpy()\n",
    "    \n",
    "    def make_sgd(lr):\n",
    "        mom = 0.99 if apply_momentum else 0.0\n",
    "        return keras.optimizers.SGD(learning_rate = lr, momentum = mom, nesterov = nesterov_momentum)        \n",
    "    \n",
    "    init_lr = eta_init_schedule(0)\n",
    "    \n",
    "    opt_async  = make_sgd(init_lr)\n",
    "    opt_dcasgd = make_sgd(init_lr) if enable_dcasgd else None\n",
    "    opt_sync   = make_sgd(init_lr) if enable_sgd else None\n",
    "        \n",
    "    q_async = deque(maxlen = max_delay + 1)         # stores gradients only\n",
    "    q_dcasgd = deque(maxlen = max_delay + 1)        # stores (gradients, model_snapshots)\n",
    "    \n",
    "    trajectory_f_async = [f0_batch]\n",
    "    trajectory_f_sync  = [f0_batch] if enable_sgd else None\n",
    "    trajectory_f_dcasgd = [f0_batch] if enable_dcasgd else None\n",
    "    \n",
    "    grad_norms_collected = []\n",
    "    eta_used = []\n",
    "\n",
    "    print(f\"\\n[A-SGD start] mu = {mu:.4f}, L = {L:.4f}, max_delay = {max_delay}, iterations = {iterations}\")\n",
    "    delay_sum = 0\n",
    "    G_local = [None for _ in M_frac]\n",
    "    tau_M = [None for _ in M_frac]\n",
    "    \n",
    "    last_M_frac_idx = 0\n",
    "    \n",
    "    nn_async  = clone_with_weights(nn)\n",
    "    nn_dcasgd = clone_with_weights(nn) if enable_dcasgd else None\n",
    "    nn_sync   = clone_with_weights(nn) if enable_sgd else None\n",
    "    \n",
    "    switched = False\n",
    "    \n",
    "    pbar = trange(iterations, desc = \"A-SGD\", leave = True)\n",
    "    for i in pbar:\n",
    "        step_idx = i + 1\n",
    "        b_idx = current_batch_index(i)\n",
    "        X_batch = X[b_idx * batch_size : (b_idx + 1) * batch_size]\n",
    "        y_batch = y[b_idx * batch_size : (b_idx + 1) * batch_size]\n",
    "        \n",
    "        if enable_dcasgd:\n",
    "        # take a detached snapshot *before* computing the gradient\n",
    "            snap_dca = [tf.stop_gradient(v.read_value()) for v in nn_dcasgd.trainable_variables]\n",
    "            g_dca, _ = evaluate_gradient(nn_dcasgd, loss_fn, X_batch, y_batch)\n",
    "            q_dcasgd.append((g_dca, snap_dca))\n",
    "        \n",
    "        current_grad_async, _ = evaluate_gradient(nn_async, loss_fn, X_batch, y_batch)\n",
    "        \n",
    "        if enable_sgd:\n",
    "            current_grad_sync, _ = evaluate_gradient(nn_sync, loss_fn, X_batch, y_batch)\n",
    "            opt_sync.apply_gradients(zip(current_grad_sync, nn_sync.trainable_variables))\n",
    "            \n",
    "        q_async.append(current_grad_async)\n",
    "\n",
    "        delay = int(tf.random.uniform(minval = 0, maxval = max_delay + 1, shape = (), dtype = tf.int32).numpy()) if max_delay > 0 else 0\n",
    "        delay_sum += delay\n",
    "\n",
    "        # If we have enough old gradients in the queue, fetch delayed_grad\n",
    "        # Otherwise, we simulate \"lost\" gradient => skip update\n",
    "        if delay < len(q_async):\n",
    "            delayed_grad = q_async[-(delay + 1)]  # \"delay steps behind\"\n",
    "        else:\n",
    "            delayed_grad = None  # Not enough old grads => skip\n",
    "        \n",
    "        if enable_dcasgd and delay < len(q_dcasgd):\n",
    "            g_delayed, snap = q_dcasgd[-(delay + 1)]\n",
    "\n",
    "            lr_t  = float(opt_dcasgd.learning_rate.numpy())\n",
    "            lamda = float(kwargs.get(\"dcasgd_lambda\", 0.04))            # start 0.01–0.05 if LR is small\n",
    "            wd    = float(kwargs.get(\"dcasgd_weight_decay\", 0.0))\n",
    "            clipg = kwargs.get(\"dcasgd_clip_gradient\", None)            # e.g., 1.0 or None\n",
    "\n",
    "            # ---- build raw DC term with correct Δw (snapshot-based) ----\n",
    "            dc_terms = []\n",
    "            base_dirs = []\n",
    "            for w, g, w_snap in zip(nn_dcasgd.trainable_variables, g_delayed, snap):\n",
    "                if wd != 0.0:\n",
    "                    g = g + wd * w\n",
    "                if clipg is not None:\n",
    "                    g = tf.clip_by_value(g, -clipg, clipg)\n",
    "\n",
    "                delta   = w - w_snap                                    # <-- correct Δw\n",
    "                dc_term = lamda * tf.square(g) * delta                  # g^2 ⊙ Δw\n",
    "                dc_terms.append(dc_term)\n",
    "                base_dirs.append(g)\n",
    "\n",
    "            # ---- trust region: ||DC|| ≤ rho * ||g|| (prevents blow-ups / oscillations) ----\n",
    "            rho      = float(kwargs.get(\"dcasgd_comp_ratio_cap\", 0.3))  # 0.2–0.5 are safe\n",
    "            dc_norm  = tf.linalg.global_norm([tf.reshape(t, [-1]) for t in dc_terms])\n",
    "            g_norm   = tf.linalg.global_norm([tf.reshape(t, [-1]) for t in base_dirs])\n",
    "            scale_tr = tf.minimum(1.0, rho * g_norm / (dc_norm + 1e-12))\n",
    "\n",
    "            # final direction per-parameter\n",
    "            final_dirs = [g + scale_tr * dct for g, dct in zip(base_dirs, dc_terms)]\n",
    "\n",
    "            # momentum (optional; OFF at first for stability)\n",
    "            if kwargs.get(\"apply_dc_momentum\", False):\n",
    "                mom_val = 0.99  # or read from a kwarg if you prefer\n",
    "                if 'dca_mom' not in locals():\n",
    "                    dca_mom = [tf.Variable(tf.zeros_like(v), trainable=False)\n",
    "                            for v in nn_dcasgd.trainable_variables]\n",
    "                for m, fd in zip(dca_mom, final_dirs):\n",
    "                    m.assign(m * mom_val - lr_t * fd)\n",
    "                steps = dca_mom\n",
    "            else:\n",
    "                steps = [-lr_t * fd for fd in final_dirs]\n",
    "\n",
    "            # apply updates\n",
    "            for w, step in zip(nn_dcasgd.trainable_variables, steps):\n",
    "                w.assign_add(step)\n",
    "\n",
    "                \n",
    "        # apply the delayed gradient if available\n",
    "        if delayed_grad is not None:\n",
    "            opt_async.apply_gradients(zip(delayed_grad, nn_async.trainable_variables))\n",
    "        # else: skip (simulate lost gradient)\n",
    "        \n",
    "        f_val_async = evaluate_objective(nn_async, loss_fn, X_batch, y_batch).numpy()        \n",
    "        trajectory_f_async.append(f_val_async)\n",
    "        \n",
    "        if enable_sgd:\n",
    "            f_val_sync = evaluate_objective(nn_sync, loss_fn, X_batch, y_batch).numpy()\n",
    "            trajectory_f_sync.append(f_val_sync)\n",
    "        if enable_dcasgd:\n",
    "            f_val_dcasgd = evaluate_objective(nn_dcasgd, loss_fn, X_batch, y_batch).numpy()\n",
    "            trajectory_f_dcasgd.append(f_val_dcasgd)\n",
    "\n",
    "        avg_delay_so_far = delay_sum / step_idx\n",
    "        \n",
    "        if delayed_grad is not None:\n",
    "            grad_norm = tf.linalg.global_norm(delayed_grad)\n",
    "            grad_norms_collected.append(grad_norm.numpy())\n",
    "        else:\n",
    "            grad_norm = None\n",
    "\n",
    "        lr_t = eta_init_schedule(step_idx)\n",
    "        opt_async.learning_rate  = lr_t\n",
    "        if enable_dcasgd: opt_dcasgd.learning_rate = dc_asgd_schedule(step_idx)\n",
    "        if enable_sgd:    opt_sync.learning_rate   = lr_t\n",
    "        \n",
    "        M = f0_batch * M_frac[last_M_frac_idx] if last_M_frac_idx < M_frac.shape[0] else None\n",
    "        condition = (M is not None) and (f_val_async < M)\n",
    "        \n",
    "        if condition or switched:\n",
    "            if grad_norm is None:\n",
    "                lr_t = eta_init_schedule(step_idx)\n",
    "                opt_async.learning_rate  = lr_t\n",
    "                if enable_dcasgd: opt_dcasgd.learning_rate = dc_asgd_schedule(step_idx)\n",
    "                if enable_sgd:    opt_sync.learning_rate   = lr_t\n",
    "            \n",
    "            elif condition:\n",
    "                if G_local[last_M_frac_idx] is None:\n",
    "                    G_local[last_M_frac_idx] = grad_norms_collected[-1]\n",
    "                if tau_M[last_M_frac_idx] is None:\n",
    "                    tau_M[last_M_frac_idx] = step_idx\n",
    "                if dynamic_lr:\n",
    "                    if not switched:\n",
    "                        desc = pbar.desc\n",
    "                        pbar.set_description(f\"{desc} [switched to dynamic lr]\")\n",
    "                        switched = True\n",
    "                        \n",
    "                last_M_frac_idx += 1\n",
    "            \n",
    "            elif switched:\n",
    "                lr = eta_fn(f_val_async, k, mu, L, sigma_sq, G_local[last_M_frac_idx - 1], max_delay,\n",
    "                            H_max = hessian_trace, clip_factor = clip_factor)\n",
    "                    \n",
    "                if clip_value is not None:\n",
    "                    lr = tf.clip_by_value(lr, 0, clip_value)\n",
    "                    \n",
    "                opt_async.learning_rate = lr\n",
    "                \n",
    "                if enable_sgd:\n",
    "                    opt_sync.learning_rate = lr\n",
    "                \n",
    "        eta_used.append(opt_async.learning_rate.numpy())\n",
    "                \n",
    "        parts = [f\"eta = {float(opt_async.learning_rate.numpy()):.4g}\",\n",
    "                 f\"avg_delay = {delay_sum/step_idx:.2f}\",\n",
    "                 f\"asgd = {f_val_async:.4f}\"]\n",
    "        \n",
    "        if enable_sgd:\n",
    "            parts.append(f\"sgd = {f_val_sync:.4f}\")\n",
    "        \n",
    "        if enable_dcasgd:\n",
    "            parts.append(f\"dcasgd = {f_val_dcasgd:.4f}\")\n",
    "            parts.append(f\"dcasgd lr = {opt_dcasgd.learning_rate.numpy():.4g}\")\n",
    "        \n",
    "        if (last_M_frac_idx > 0) and (G_local[last_M_frac_idx - 1] is not None):\n",
    "            parts.append(f\"G_local = {G_local[last_M_frac_idx - 1]:.2f} - last index = {last_M_frac_idx - 1}\")\n",
    "        \n",
    "        pbar.set_postfix_str(\" - \".join(parts))\n",
    "                    \n",
    "    pbar.close()\n",
    "\n",
    "    trajectory_f_async = np.asarray(trajectory_f_async, dtype = np.float32)\n",
    "    if enable_sgd:\n",
    "        trajectory_f_sync = np.asarray(trajectory_f_sync, dtype = np.float32)\n",
    "    if enable_dcasgd:\n",
    "        trajectory_f_dcasgd = np.asarray(trajectory_f_dcasgd, dtype = np.float32)\n",
    "        \n",
    "    eta_used = np.asarray(eta_used)\n",
    "    grad_norms_collected = np.asarray(grad_norms_collected)\n",
    "\n",
    "    return (trajectory_f_async, trajectory_f_sync, trajectory_f_dcasgd, eta_used), grad_norms_collected, (G_local, tau_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_gradient_variance(\n",
    "                                    nn,\n",
    "                                    X, \n",
    "                                    y, \n",
    "                                    batch_size, \n",
    "                                    num_batches = 10,\n",
    "                                    use_full_gradient = True\n",
    "                              ):\n",
    "    \"\"\"\n",
    "    Estimates trace(Cov[G]) = E[||g - E[g]||^2],\n",
    "    by comparing mini-batch gradients to a reference gradient.\n",
    "\n",
    "    Args:\n",
    "        nn (tf.keras.Model): The neural network model.\n",
    "        X (tf.Tensor): Input data.\n",
    "        y (tf.Tensor): One-hot encoded target labels.\n",
    "        batch_size (int): Size of the mini-batch for stochastic gradient estimation.\n",
    "        num_batches (int): Number of mini-batches to sample for the estimation.\n",
    "        use_full_gradient (bool): If True, compute the gradient using the entire dataset (or a large chunk).\n",
    "                                  If False, approximate E[g] by first computing an average over some large subset.\n",
    "\n",
    "    Returns:\n",
    "        float: Estimated trace of the covariance matrix of the gradients.\n",
    "    \"\"\"\n",
    "    \n",
    "    if num_batches < 0:\n",
    "        num_batches = np.ceil(X.shape[0] / batch_size).astype(np.int32)\n",
    "    \n",
    "    # 1. Determine the \"reference\" dataset for the gradient\n",
    "    if use_full_gradient:\n",
    "        # either the entire data if feasible...\n",
    "        X_ref, y_ref = X, y\n",
    "    else:\n",
    "        # ...or a large random subset if your dataset is huge\n",
    "        large_batch_size = min(4096, X.shape[0])\n",
    "        indices_ref = tf.random.shuffle(tf.range(X.shape[0]))[:large_batch_size]\n",
    "        X_ref = tf.gather(X, indices_ref)\n",
    "        y_ref = tf.gather(y, indices_ref)\n",
    "\n",
    "    # 2. Compute the reference gradient (acts like E[g])\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred_ref = nn(X_ref, training = True)  # forward pass\n",
    "        loss_ref = tf.reduce_mean(\n",
    "            tf.keras.losses.categorical_crossentropy(y_ref, y_pred_ref)\n",
    "        )\n",
    "    ref_grads = tape.gradient(loss_ref, nn.trainable_variables)\n",
    "\n",
    "    # 3. Sample multiple mini-batches, compute their gradients, track sum of squared diffs\n",
    "    variance_sum = 0.0  # accumulates sum of ||g_batch - g_ref||^2\n",
    "    pbar = trange(num_batches, desc = \"Estimating gradient variance\")\n",
    "    \n",
    "    for i in pbar:\n",
    "        # Randomly select a mini-batch from the reference set\n",
    "        indices = tf.random.shuffle(tf.range(tf.shape(X_ref)[0]))[:batch_size]\n",
    "        X_batch = tf.gather(X_ref, indices)\n",
    "        y_batch = tf.gather(y_ref, indices)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred_batch = nn(X_batch, training = True)\n",
    "            loss_batch = tf.reduce_mean(\n",
    "                tf.keras.losses.categorical_crossentropy(y_batch, y_pred_batch)\n",
    "            )\n",
    "        batch_grads = tape.gradient(loss_batch, nn.trainable_variables)\n",
    "\n",
    "        # Squared difference between mini-batch gradient and reference gradient\n",
    "        batch_var = 0.0\n",
    "        for bg, rg in zip(batch_grads, ref_grads):\n",
    "            # guard against a None gradient\n",
    "            if bg is not None and rg is not None:\n",
    "                batch_var += tf.reduce_sum(tf.square(bg - rg))\n",
    "\n",
    "        variance_sum += batch_var.numpy()\n",
    "        \n",
    "        pbar.set_postfix_str(f\"variance so far: {variance_sum / (i+1):.4f}\")\n",
    "\n",
    "    # 4. Average over the total number of batches to estimate the trace\n",
    "    variance_estimate = variance_sum / num_batches\n",
    "    return variance_estimate / nn.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_asgd(dataset,\n",
    "             nn_type,\n",
    "             hessian_trace, \n",
    "             iterations, max_delay,\n",
    "             batch_size,\n",
    "             eta_init_schedule,\n",
    "             dc_asgd_schedule,\n",
    "             M_frac,\n",
    "             f_star = None, sigma_sq = None,\n",
    "             mu = None, L = None,\n",
    "             dynamic_lr = False,\n",
    "             clip_factor = 0.9,\n",
    "             clip_value = 4e-4,\n",
    "             num_batches_to_estimate_grad_variance = 10,\n",
    "             enable_sgd = True,\n",
    "             enable_dcasgd = True,\n",
    "             dcasgd_lambda = 0.04,\n",
    "             dcasgd_clip_gradient = None,\n",
    "             dcasgd_comp_ratio_cap = 0.3,\n",
    "             apply_momentum = False,\n",
    "             nesterov_momentum = False,\n",
    "             apply_dc_momentum = False,\n",
    "             calculate_bounds = True):\n",
    "    \n",
    "    display(f\"Called `run_asgd()` with:\")\n",
    "    display(HTML('<pre>' + '\\n'.join([f'{k} = {v}' for (k, v) in locals().items()]) + '</pre>'))\n",
    "    \n",
    "    if dataset == 'cifar10':\n",
    "        (X, y), _ = obtain_cifar10()\n",
    "    elif dataset == 'cifar100':\n",
    "        (X, y), _ = obtain_cifar100()\n",
    "    else:\n",
    "        raise ValueError(f\"`dataset` must be either 'cifar10' or 'cigar100'. Found {dataset}\")\n",
    "    \n",
    "    if dynamic_lr:\n",
    "        assert clip_factor is not None\n",
    "    \n",
    "    if nn_type == 'dense':\n",
    "        nn = create_dense_nn(input_shape = X.shape[1:], width = 1024, num_classes = y.shape[1])\n",
    "    elif nn_type == 'vgg':\n",
    "        nn = create_vgg_nn(input_shape = X.shape[1:], num_classes = y.shape[1])\n",
    "    \n",
    "    loss_fn = keras.losses.CategoricalCrossentropy(from_logits = False, name = 'ce_loss')\n",
    "    \n",
    "    if f_star is None:\n",
    "        nn_copy = keras.models.clone_model(nn)\n",
    "        \n",
    "        f_star, _ = get_minimum_loss(nn_copy, loss_fn, \n",
    "                                     train_data = (X, y), \n",
    "                                     metrics = keras.metrics.CategoricalAccuracy(name = 'accuracy'), \n",
    "                                     batch_size = batch_size, num_epochs = 100)\n",
    "        del nn_copy\n",
    "    \n",
    "    print(f\"f* = {f_star:.4f}\")\n",
    "    \n",
    "    dim = nn.count_params()    \n",
    "    \n",
    "    if sigma_sq is None:\n",
    "        use_full_gradient = True if nn_type == 'dense_nn' else False\n",
    "        sigma_sq = estimate_gradient_variance(nn, X, y, batch_size = 4096,\n",
    "                                              num_batches = num_batches_to_estimate_grad_variance,\n",
    "                                              use_full_gradient = use_full_gradient)\n",
    "        sigma_sq_mean = sigma_sq\n",
    "        print(f\"Estimated sigma_sq = {sigma_sq}\")\n",
    "    elif isinstance(sigma_sq, np.ndarray):\n",
    "        sigma_sq_mean = sigma_sq.mean()\n",
    "    elif isinstance(sigma_sq, tf.Tensor):\n",
    "        sigma_sq_mean = tf.reduce_mean(sigma_sq).numpy()\n",
    "    else:\n",
    "        sigma_sq_mean = sigma_sq\n",
    "\n",
    "    f0_diff = evaluate_objective(nn, loss_fn, X, y, batch_size = 4096).numpy() - f_star\n",
    "    print(f\"Mean Initial Objective Difference: {f0_diff.mean():.5f}\")\n",
    "    \n",
    "    if mu is None or L is None:\n",
    "        mu_est, L_est = get_mu_and_L(optimizer_init_learning_rate = 0.01, momentum = 0.99, L_estimator_iterations = 10)\n",
    "        \n",
    "    if mu is None:\n",
    "        mu = mu_est\n",
    "    if L is None:\n",
    "        L = L_est\n",
    "    \n",
    "    ((trajectory_f_1_async, trajectory_f_1_sync, trajectory_f_1_dcasgd, learning_rates_1), \n",
    "      grad_norms_collected, (G_locals, tau_Ms)) = asgd(nn = nn, \n",
    "                                                       mu = mu, \n",
    "                                                       L = L, \n",
    "                                                       hessian_trace = hessian_trace,\n",
    "                                                       max_delay = max_delay, \n",
    "                                                       sigma_sq = sigma_sq,  \n",
    "                                                       iterations = iterations, \n",
    "                                                       eta_init_schedule = eta_init_schedule,\n",
    "                                                       dc_asgd_schedule = dc_asgd_schedule,\n",
    "                                                       M_frac = M_frac,\n",
    "                                                       dynamic_lr = dynamic_lr,\n",
    "                                                       clip_factor = clip_factor,\n",
    "                                                       clip_value = clip_value,\n",
    "                                                       train_data = (X, y),\n",
    "                                                       loss_fn = loss_fn,\n",
    "                                                       enable_sgd = enable_sgd,\n",
    "                                                       enable_dcasgd = enable_dcasgd,\n",
    "                                                       apply_momentum = apply_momentum,\n",
    "                                                       nesterov_momentum = nesterov_momentum,\n",
    "                                                       apply_dc_momentum = apply_dc_momentum,\n",
    "                                                       batch_size = batch_size,\n",
    "                                                       dcasgd_lambda = dcasgd_lambda,\n",
    "                                                       dcasgd_clip_gradient = dcasgd_clip_gradient,\n",
    "                                                       dcasgd_comp_ratio_cap = dcasgd_comp_ratio_cap)\n",
    "      \n",
    "    \n",
    "    print(f\"Trajectories Obtained!!!\")\n",
    "    \n",
    "    print(f\"[Grad Norm Stats]: max: {grad_norms_collected.max():.4f} - mean: {grad_norms_collected.mean():.4f} - stddev: {grad_norms_collected.std():.4f} - min: {grad_norms_collected.min():.4f}\")\n",
    "    \n",
    "    if calculate_bounds:\n",
    "        k = dim\n",
    "        T = max_delay\n",
    "        \n",
    "        bounds_1 = []\n",
    "        kappa_values = []\n",
    "        \n",
    "        for G_local, tau_M in zip(G_locals, tau_Ms):\n",
    "            if tau_M is None:\n",
    "                bound = np.asarray([np.nan for _ in range(iterations + 1)])\n",
    "                bounds_1.append(bound)\n",
    "                continue\n",
    "            \n",
    "            block_ids = build_block_ids(iterations, T, start = tau_M)\n",
    "            kappa, _ = kappa_fn_tf(\n",
    "                                        np.asarray(learning_rates_1)[np.newaxis, ...], mu = mu, L = L, sigma_sq = sigma_sq,\n",
    "                                        T = T, G_local = [G_local],\n",
    "                                        hess_tr = hessian_trace, tau_M = tau_M, block_ids = block_ids\n",
    "                                  )\n",
    "            kappa = kappa.numpy()\n",
    "            kappa_values.append(kappa)\n",
    "            bound = discrete_time_pl_bound_fast_tf(trajectory_f_1_async[tau_M], kappa, mu, learning_rates_1, tau_M = tau_M).numpy()\n",
    "            bound = np.pad(bound, (tau_M, 0), mode = 'constant', constant_values = np.nan)\n",
    "            \n",
    "            bounds_1.append(bound)\n",
    "            \n",
    "        bounds_1 = np.asarray(bounds_1).astype(np.float64)\n",
    "        kappa_values = np.asarray(kappa_values)\n",
    "    else:\n",
    "        bounds_1 = None    \n",
    "    \n",
    "    \n",
    "    return (\n",
    "                trajectory_f_1_async, \n",
    "                trajectory_f_1_sync,\n",
    "                trajectory_f_1_dcasgd,\n",
    "                bounds_1, \n",
    "                learning_rates_1,\n",
    "            ), (mu, L, f0_diff, sigma_sq, dim, G_locals, tau_Ms, grad_norms_collected, kappa_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar100'\n",
    "nn_type = 'vgg'\n",
    "iterations = 25_000\n",
    "max_delay = 10\n",
    "batch_size = 1024\n",
    "f_star = np.float32(0)\n",
    "sigma_sq = None\n",
    "\n",
    "mu, L, hessian_trace = 0.17145, 33, 26250\n",
    "\n",
    "eta1 = lambda t: 2e-8 * t + 1e-4 if t < 10000 else -np.inf\n",
    "eta2 = lambda t: 0.0003 * np.exp(-0.00004 * (t - 10000)) if t >= 10000 else -np.inf\n",
    "# eta3 = lambda t: 5e-5 * t if t <= 10000 else -np.inf\n",
    "\n",
    "eta_function = lambda t: max(eta1(t), eta2(t))\n",
    "\n",
    "eta_init_schedule = eta_function\n",
    "dc_asgd_schedule = lambda t: min(1e-5 + (1e-4 - 1e-5) / (0.1 * iterations) * t, 1e-4)\n",
    "        \n",
    "\n",
    "M_frac = [0.5, 0.3, 0.1]\n",
    "# M_frac = [0.95]\n",
    "\n",
    "dynamic_lr = True\n",
    "clip_factor = 0.15          # <-- Use when dynamic_lr is set to True\n",
    "clip_value = 4e-4\n",
    "num_batches_to_estimate_grad_variance = 10\n",
    "enable_sgd = True\n",
    "\n",
    "enable_dcasgd = False\n",
    "dcasgd_lambda = 0.04\n",
    "dcasgd_clip_gradient = 5.0\n",
    "apply_dc_momentum = False\n",
    "dcasgd_comp_ratio_cap = 0.3\n",
    "\n",
    "calculate_bounds = True\n",
    "apply_momentum = True\n",
    "nesterov_momentum = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((_, hessian_trace_estimate), \n",
    "#  trace_vals_hessian) = estimate_hessian_trace(nn_type = nn_type,\n",
    "#                                               data = dataset,\n",
    "#                                               optimizer_init_learning_rate = 1e-4, \n",
    "#                                               num_trace_vectors = 30,\n",
    "#                                               batch_size = 4096,\n",
    "#                                               num_epochs = 5)\n",
    "\n",
    "# mu_estimate = estimate_pl_constant(nn_type = nn_type,\n",
    "#                                    data = dataset,\n",
    "#                                    batch_size = 4096,\n",
    "#                                    optimizer_init_learning_rate = 1e-4,\n",
    "#                                    num_epochs = 50,\n",
    "#                                    burnin_steps = 0,\n",
    "#                                    min_loss_gap = 0.05,\n",
    "#                                    display_ncols = 100)\n",
    "\n",
    "# L_estimate = estimate_minimum_L_smoothness_constant(nn_type = nn_type,\n",
    "#                                                     data = dataset,\n",
    "#                                                     optimizer_init_learning_rate = 1e-4,\n",
    "#                                                     optimizer_momentum = 0.99,\n",
    "#                                                     L_estimator_iterations = 100,\n",
    "#                                                     batch_size = 512,\n",
    "#                                                     num_epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Called `run_asgd()` with:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>dataset = cifar100\n",
       "nn_type = vgg\n",
       "hessian_trace = 26250\n",
       "iterations = 25000\n",
       "max_delay = 10\n",
       "batch_size = 1024\n",
       "eta_init_schedule = <function <lambda> at 0x73ce2ab856c0>\n",
       "dc_asgd_schedule = <function <lambda> at 0x73ce2ab856c0>\n",
       "M_frac = [0.5, 0.3, 0.1]\n",
       "f_star = 0.0\n",
       "sigma_sq = 1e-13\n",
       "mu = 0.17145\n",
       "L = 33\n",
       "dynamic_lr = True\n",
       "clip_factor = 0.15\n",
       "clip_value = 0.0004\n",
       "num_batches_to_estimate_grad_variance = 10\n",
       "enable_sgd = True\n",
       "enable_dcasgd = False\n",
       "dcasgd_lambda = 0.04\n",
       "dcasgd_clip_gradient = 5.0\n",
       "dcasgd_comp_ratio_cap = 0.3\n",
       "apply_momentum = True\n",
       "nesterov_momentum = True\n",
       "apply_dc_momentum = False\n",
       "calculate_bounds = True</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received `num_classes` = 100\n",
      "f* = 0.0000\n",
      "Mean Initial Objective Difference: 4.87558\n",
      "A-SGD batch size: 1024\n",
      "\n",
      "[A-SGD start] mu = 0.1714, L = 33.0000, max_delay = 10, iterations = 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A-SGD:   0%|          | 0/25000 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755842916.030601   98582 service.cc:145] XLA service 0x32b05c40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1755842916.030629   98582 service.cc:153]   StreamExecutor device (0): NVIDIA H100 80GB HBM3, Compute Capability 9.0\n",
      "I0000 00:00:1755842916.096940   98582 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "A-SGD [switched to dynamic lr]: 100%|██████████| 25000/25000 [37:27<00:00, 11.12it/s, eta = 8.066e-06 - avg_delay = 5.01 - asgd = 0.0079 - sgd = 0.0000 - G_local = 4.14 - last index = 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectories Obtained!!!\n",
      "[Grad Norm Stats]: max: 23.2736 - mean: 2.6869 - stddev: 1.7324 - min: 0.3455\n"
     ]
    }
   ],
   "source": [
    "# mu, L = np.float32(mu_estimate), np.float32(L_estimate)\n",
    "# hessian_trace = np.float32(hessian_trace_estimate)\n",
    "(\n",
    "    trajectory_f_1_async,\n",
    "    trajectory_f_1_sync,\n",
    "    trajectory_f_1_dcasgd,\n",
    "    bounds_1, \n",
    "    learning_rates_schedule,\n",
    "), (mu, L, f0_diff, sigma_sq, k, G_locals, tau_Ms, grad_norms_collected, kappa_values) = run_asgd(dataset,\n",
    "                                                                                                  nn_type,\n",
    "                                                                                                  hessian_trace, \n",
    "                                                                                                  iterations, max_delay,\n",
    "                                                                                                  batch_size,\n",
    "                                                                                                  M_frac = M_frac,\n",
    "                                                                                                  f_star = f_star, \n",
    "                                                                                                  sigma_sq = 1e-13,\n",
    "                                                                                                  mu = mu, L = L,\n",
    "                                                                                                  num_batches_to_estimate_grad_variance = num_batches_to_estimate_grad_variance,\n",
    "                                                                                                  eta_init_schedule = eta_init_schedule,\n",
    "                                                                                                  dc_asgd_schedule = eta_init_schedule,\n",
    "                                                                                                  dynamic_lr = dynamic_lr,\n",
    "                                                                                                  clip_factor = clip_factor,\n",
    "                                                                                                  clip_value = clip_value,\n",
    "                                                                                                  enable_sgd = enable_sgd,\n",
    "                                                                                                  enable_dcasgd = enable_dcasgd,\n",
    "                                                                                                  dcasgd_lambda = dcasgd_lambda,\n",
    "                                                                                                  dcasgd_clip_gradient = dcasgd_clip_gradient,\n",
    "                                                                                                  dcasgd_comp_ratio_cap = dcasgd_comp_ratio_cap,\n",
    "                                                                                                  apply_momentum = apply_momentum,\n",
    "                                                                                                  nesterov_momentum = nesterov_momentum,\n",
    "                                                                                                  apply_dc_momentum = apply_dc_momentum,\n",
    "                                                                                                  calculate_bounds = calculate_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 501)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu_bound = np.where(np.isnan(bounds_1), np.inf, bounds_1)\n",
    "lu_bound = lu_bound.min(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (8, 8))\n",
    "ax1.plot(trajectory_f_1_async, c = 'blue', label = 'A-SGD Trajectory')\n",
    "\n",
    "if enable_sgd:\n",
    "    ax1.plot(trajectory_f_1_sync, c = 'purple', label = 'SGD Trajectory')\n",
    "if enable_dcasgd:\n",
    "    ax1.plot(trajectory_f_1_dcasgd, c = 'red', label = 'DC-ASGD Trajectory')\n",
    "\n",
    "for bound in bounds_1:\n",
    "    if not (np.all(np.isnan(bound)) or np.all(np.isinf(bound))):\n",
    "        ax1.plot(bound, label = 'Upper-Bound on A-SGD Trajectory')\n",
    "\n",
    "ax1.plot(lu_bound, ls = '--', color = 'k', label = 'combined upper-bound')\n",
    "\n",
    "ax1.legend()\n",
    "ax1.grid(which = 'both')\n",
    "ax1.set_xlabel(\"Iterations\")\n",
    "ax1.set_ylabel(r\"$f(\\theta) - f(\\theta^*)$\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"./asgd_multi_bounds.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict = {\n",
    "                'trajectory_f_1_async'      : trajectory_f_1_async,\n",
    "                'trajectory_f_1_sync'       : trajectory_f_1_sync,\n",
    "                'trajectory_f_1_dcasgd'     : trajectory_f_1_dcasgd,\n",
    "                'bounds_1'                  : bounds_1, \n",
    "                'kappa_values'              : kappa_values,\n",
    "                'learning_rates_schedule'   : learning_rates_schedule, \n",
    "                'mu'                        : mu,    \n",
    "                'L'                         : L,\n",
    "                'f0_diff'                   : f0_diff,\n",
    "                'sigma_sq'                  : sigma_sq,\n",
    "                'k'                         : k,\n",
    "                'G_locals'                  : G_locals,\n",
    "                'tau_Ms'                    : tau_Ms,\n",
    "                'grad_norms_collected'      : grad_norms_collected      \n",
    "            }\n",
    "\n",
    "np.savez('params', **save_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x73cbc71b01f0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learning_rates_schedule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
